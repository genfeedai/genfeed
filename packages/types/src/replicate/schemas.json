[
  {
    "modelId": "google/nano-banana",
    "name": "NanoBanana",
    "category": "image",
    "description": "Google's latest image editing model in Gemini 2.5",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "prompt"
      ],
      "properties": {
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "x-order": 0,
          "description": "A text description of the image you want to generate"
        },
        "image_input": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "uri"
          },
          "title": "Image Input",
          "default": [],
          "x-order": 1,
          "description": "Input images to transform or use as reference (supports multiple images)"
        },
        "aspect_ratio": {
          "allOf": [
            {
              "$ref": "#/components/schemas/aspect_ratio"
            }
          ],
          "default": "match_input_image",
          "x-order": 2,
          "description": "Aspect ratio of the generated image"
        },
        "output_format": {
          "allOf": [
            {
              "$ref": "#/components/schemas/output_format"
            }
          ],
          "default": "jpg",
          "x-order": 3,
          "description": "Format of the output image"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:28.348Z"
  },
  {
    "modelId": "google/nano-banana-pro",
    "name": "NanoBananaPro",
    "category": "image",
    "description": "Google's state of the art image generation and editing model ðŸŒðŸŒ",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "prompt"
      ],
      "properties": {
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "x-order": 0,
          "description": "A text description of the image you want to generate"
        },
        "resolution": {
          "allOf": [
            {
              "$ref": "#/components/schemas/resolution"
            }
          ],
          "default": "2K",
          "x-order": 3,
          "description": "Resolution of the generated image"
        },
        "image_input": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "uri"
          },
          "title": "Image Input",
          "default": [],
          "x-order": 1,
          "description": "Input images to transform or use as reference (supports up to 14 images)"
        },
        "aspect_ratio": {
          "allOf": [
            {
              "$ref": "#/components/schemas/aspect_ratio"
            }
          ],
          "default": "match_input_image",
          "x-order": 2,
          "description": "Aspect ratio of the generated image"
        },
        "output_format": {
          "allOf": [
            {
              "$ref": "#/components/schemas/output_format"
            }
          ],
          "default": "jpg",
          "x-order": 4,
          "description": "Format of the output image"
        },
        "safety_filter_level": {
          "allOf": [
            {
              "$ref": "#/components/schemas/safety_filter_level"
            }
          ],
          "default": "block_only_high",
          "x-order": 5,
          "description": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:28.627Z"
  },
  {
    "modelId": "google/veo-3.1-fast",
    "name": "Veo31Fast",
    "category": "video",
    "description": "New and improved version of Veo 3 Fast, with higher-fidelity video, context-aware audio and last frame support",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "prompt"
      ],
      "properties": {
        "seed": {
          "type": "integer",
          "title": "Seed",
          "x-order": 8,
          "nullable": true,
          "description": "Random seed. Omit for random generations"
        },
        "image": {
          "type": "string",
          "title": "Image",
          "format": "uri",
          "x-order": 3,
          "nullable": true,
          "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."
        },
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "x-order": 0,
          "description": "Text prompt for video generation"
        },
        "duration": {
          "allOf": [
            {
              "$ref": "#/components/schemas/duration"
            }
          ],
          "default": 8,
          "x-order": 2,
          "description": "Video duration in seconds"
        },
        "last_frame": {
          "type": "string",
          "title": "Last Frame",
          "format": "uri",
          "x-order": 4,
          "nullable": true,
          "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."
        },
        "resolution": {
          "allOf": [
            {
              "$ref": "#/components/schemas/resolution"
            }
          ],
          "default": "1080p",
          "x-order": 6,
          "description": "Resolution of the generated video"
        },
        "aspect_ratio": {
          "allOf": [
            {
              "$ref": "#/components/schemas/aspect_ratio"
            }
          ],
          "default": "16:9",
          "x-order": 1,
          "description": "Video aspect ratio"
        },
        "generate_audio": {
          "type": "boolean",
          "title": "Generate Audio",
          "default": true,
          "x-order": 7,
          "description": "Generate audio with the video"
        },
        "negative_prompt": {
          "type": "string",
          "title": "Negative Prompt",
          "x-order": 5,
          "nullable": true,
          "description": "Description of what to exclude from the generated video"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:28.811Z"
  },
  {
    "modelId": "google/veo-3.1",
    "name": "Veo31",
    "category": "video",
    "description": "New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "prompt"
      ],
      "properties": {
        "seed": {
          "type": "integer",
          "title": "Seed",
          "x-order": 9,
          "nullable": true,
          "description": "Random seed. Omit for random generations"
        },
        "image": {
          "type": "string",
          "title": "Image",
          "format": "uri",
          "x-order": 3,
          "nullable": true,
          "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."
        },
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "x-order": 0,
          "description": "Text prompt for video generation"
        },
        "duration": {
          "allOf": [
            {
              "$ref": "#/components/schemas/duration"
            }
          ],
          "default": 8,
          "x-order": 2,
          "description": "Video duration in seconds"
        },
        "last_frame": {
          "type": "string",
          "title": "Last Frame",
          "format": "uri",
          "x-order": 4,
          "nullable": true,
          "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."
        },
        "resolution": {
          "allOf": [
            {
              "$ref": "#/components/schemas/resolution"
            }
          ],
          "default": "1080p",
          "x-order": 7,
          "description": "Resolution of the generated video"
        },
        "aspect_ratio": {
          "allOf": [
            {
              "$ref": "#/components/schemas/aspect_ratio"
            }
          ],
          "default": "16:9",
          "x-order": 1,
          "description": "Video aspect ratio"
        },
        "generate_audio": {
          "type": "boolean",
          "title": "Generate Audio",
          "default": true,
          "x-order": 8,
          "description": "Generate audio with the video"
        },
        "negative_prompt": {
          "type": "string",
          "title": "Negative Prompt",
          "x-order": 6,
          "nullable": true,
          "description": "Description of what to exclude from the generated video"
        },
        "reference_images": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "uri"
          },
          "title": "Reference Images",
          "default": [],
          "x-order": 5,
          "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:29.006Z"
  },
  {
    "modelId": "kwaivgi/kling-v2.5-turbo-pro",
    "name": "KlingV25TurboPro",
    "category": "video",
    "description": "Kling 2.5 Turbo Pro: Unlock pro-level text-to-video and image-to-video creation with smooth motion, cinematic depth, and remarkable prompt adherence.",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "prompt"
      ],
      "properties": {
        "image": {
          "type": "string",
          "title": "Image",
          "format": "uri",
          "x-order": 6,
          "nullable": true,
          "deprecated": true,
          "description": "Deprecated: Use start_image instead."
        },
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "x-order": 0,
          "description": "Text prompt for video generation"
        },
        "duration": {
          "allOf": [
            {
              "$ref": "#/components/schemas/duration"
            }
          ],
          "default": 5,
          "x-order": 5,
          "description": "Duration of the video in seconds"
        },
        "end_image": {
          "type": "string",
          "title": "End Image",
          "format": "uri",
          "x-order": 3,
          "description": "Last frame of the video"
        },
        "start_image": {
          "type": "string",
          "title": "Start Image",
          "format": "uri",
          "x-order": 2,
          "description": "First frame of the video"
        },
        "aspect_ratio": {
          "allOf": [
            {
              "$ref": "#/components/schemas/aspect_ratio"
            }
          ],
          "default": "16:9",
          "x-order": 4,
          "description": "Aspect ratio of the video. Ignored if start_image is provided."
        },
        "negative_prompt": {
          "type": "string",
          "title": "Negative Prompt",
          "default": "",
          "x-order": 1,
          "description": "Things you do not want to see in the video"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:29.185Z"
  },
  {
    "modelId": "kwaivgi/kling-v2.6-motion-control",
    "name": "KlingV26MotionControl",
    "category": "video",
    "description": "Enables precise control of character actions and expressions from a reference image.",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "image",
        "video"
      ],
      "properties": {
        "mode": {
          "allOf": [
            {
              "$ref": "#/components/schemas/mode"
            }
          ],
          "default": "std",
          "x-order": 4,
          "description": "Video generation mode. 'std': Standard mode (cost-effective). 'pro': Professional mode (higher quality)."
        },
        "image": {
          "type": "string",
          "title": "Image",
          "format": "uri",
          "x-order": 1,
          "description": "Reference image. The characters, backgrounds, and other elements in the generated video are based on the reference image. Supports .jpg/.jpeg/.png, max 10MB, dimensions 340px-3850px, aspect ratio 1:2.5 to 2.5:1."
        },
        "video": {
          "type": "string",
          "title": "Video",
          "format": "uri",
          "x-order": 2,
          "description": "Reference video. The character actions in the generated video are consistent with the reference video. Supports .mp4/.mov, max 100MB, 3-30 seconds duration depending on character_orientation."
        },
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "default": "",
          "x-order": 0,
          "description": "Text prompt for video generation. You can add elements to the screen and achieve motion effects through prompt words."
        },
        "keep_original_sound": {
          "type": "boolean",
          "title": "Keep Original Sound",
          "default": true,
          "x-order": 5,
          "description": "Whether to keep the original sound of the video"
        },
        "character_orientation": {
          "allOf": [
            {
              "$ref": "#/components/schemas/character_orientation"
            }
          ],
          "default": "image",
          "x-order": 3,
          "description": "Generate the orientation of the characters in the video. 'image': same orientation as the person in the picture (max 10s video). 'video': consistent with the orientation of the characters in the video (max 30s video)."
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:29.367Z"
  },
  {
    "modelId": "meta/meta-llama-3.1-405b-instruct",
    "name": "MetaLlama31",
    "category": "llm",
    "description": "Meta's flagship 405 billion parameter language model, fine-tuned for chat completions",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "properties": {
        "top_k": {
          "type": "integer",
          "title": "Top K",
          "default": 50,
          "x-order": 6,
          "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering)."
        },
        "top_p": {
          "type": "number",
          "title": "Top P",
          "default": 0.9,
          "x-order": 5,
          "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)."
        },
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "default": "",
          "x-order": 0,
          "description": "Prompt"
        },
        "max_tokens": {
          "type": "integer",
          "title": "Max Tokens",
          "default": 512,
          "x-order": 3,
          "description": "The maximum number of tokens the model should generate as output."
        },
        "min_tokens": {
          "type": "integer",
          "title": "Min Tokens",
          "default": 0,
          "x-order": 2,
          "description": "The minimum number of tokens the model should generate as output."
        },
        "temperature": {
          "type": "number",
          "title": "Temperature",
          "default": 0.6,
          "x-order": 4,
          "description": "The value used to modulate the next token probabilities."
        },
        "system_prompt": {
          "type": "string",
          "title": "System Prompt",
          "default": "You are a helpful assistant.",
          "x-order": 1,
          "description": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models."
        },
        "stop_sequences": {
          "type": "string",
          "title": "Stop Sequences",
          "default": "",
          "x-order": 9,
          "description": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'."
        },
        "prompt_template": {
          "type": "string",
          "title": "Prompt Template",
          "default": "",
          "x-order": 10,
          "description": "A template to format the prompt with. If not provided, the default prompt template will be used."
        },
        "presence_penalty": {
          "type": "number",
          "title": "Presence Penalty",
          "default": 0,
          "x-order": 7,
          "description": "Presence penalty"
        },
        "frequency_penalty": {
          "type": "number",
          "title": "Frequency Penalty",
          "default": 0,
          "x-order": 8,
          "description": "Frequency penalty"
        }
      }
    },
    "outputSchema": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "title": "Output",
      "x-cog-array-type": "iterator",
      "x-cog-array-display": "concatenate"
    },
    "fetchedAt": "2026-01-16T03:17:29.545Z"
  },
  {
    "modelId": "luma/reframe-image",
    "name": "LumaReframeImage",
    "category": "reframe",
    "description": "Change the aspect ratio of any photo using AI (not cropping)",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "properties": {
        "image": {
          "type": "string",
          "title": "Image",
          "format": "uri",
          "description": "The image to reframe"
        },
        "model": {
          "allOf": [
            {
              "$ref": "#/components/schemas/model"
            }
          ],
          "default": "photon-flash-1",
          "x-order": 3,
          "description": "The model to use for the reframe generation"
        },
        "x_end": {
          "type": "integer",
          "title": "X End",
          "description": "The x end of the crop bounds, in pixels. Defines the right boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content."
        },
        "y_end": {
          "type": "integer",
          "title": "Y End",
          "description": "The y end of the crop bounds, in pixels. Defines the bottom boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content."
        },
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "description": "A prompt to guide the reframing generation"
        },
        "x_start": {
          "type": "integer",
          "title": "X Start",
          "description": "The x start of the crop bounds, in pixels. Defines the left boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content."
        },
        "y_start": {
          "type": "integer",
          "title": "Y Start",
          "description": "The y start of the crop bounds, in pixels. Defines the top boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content."
        },
        "image_url": {
          "type": "string",
          "title": "Image Url",
          "deprecated": true,
          "description": "URL of the image to reframe"
        },
        "aspect_ratio": {
          "allOf": [
            {
              "$ref": "#/components/schemas/aspect_ratio"
            }
          ],
          "default": "16:9",
          "x-order": 1,
          "description": "Aspect ratio of the output"
        },
        "grid_position_x": {
          "type": "integer",
          "title": "Grid Position X",
          "description": "The x position of the input in the grid, in pixels. Controls horizontal positioning of the source within the target output dimensions."
        },
        "grid_position_y": {
          "type": "integer",
          "title": "Grid Position Y",
          "description": "The y position of the input in the grid, in pixels. Controls vertical positioning of the source within the target output dimensions."
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:29.731Z"
  },
  {
    "modelId": "luma/reframe-video",
    "name": "LumaReframeVideo",
    "category": "reframe",
    "description": "Change the aspect ratio of any video up to 30 seconds long, outputs will be 720p",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "properties": {
        "video": {
          "type": "string",
          "title": "Video",
          "format": "uri",
          "description": "The video to reframe. Maximum video duration is 10 seconds."
        },
        "x_end": {
          "type": "integer",
          "title": "X End",
          "description": "The x end of the crop bounds, in pixels. Defines the right boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content."
        },
        "y_end": {
          "type": "integer",
          "title": "Y End",
          "description": "The y end of the crop bounds, in pixels. Defines the bottom boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content."
        },
        "prompt": {
          "type": "string",
          "title": "Prompt",
          "description": "A prompt to guide the reframing generation"
        },
        "x_start": {
          "type": "integer",
          "title": "X Start",
          "description": "The x start of the crop bounds, in pixels. Defines the left boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content."
        },
        "y_start": {
          "type": "integer",
          "title": "Y Start",
          "description": "The y start of the crop bounds, in pixels. Defines the top boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content."
        },
        "video_url": {
          "type": "string",
          "title": "Video Url",
          "deprecated": true,
          "description": "URL of the video to reframe. Maximum video duration is 10 seconds."
        },
        "aspect_ratio": {
          "allOf": [
            {
              "$ref": "#/components/schemas/aspect_ratio"
            }
          ],
          "default": "16:9",
          "x-order": 1,
          "description": "Aspect ratio of the output"
        },
        "grid_position_x": {
          "type": "integer",
          "title": "Grid Position X",
          "description": "The x position of the input in the grid, in pixels. Controls horizontal positioning of the source within the target output dimensions."
        },
        "grid_position_y": {
          "type": "integer",
          "title": "Grid Position Y",
          "description": "The y position of the input in the grid, in pixels. Controls vertical positioning of the source within the target output dimensions."
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:29.916Z"
  },
  {
    "modelId": "sync/lipsync-2",
    "name": "Lipsync2",
    "category": "lipsync",
    "description": "Generate realistic lipsyncs with Sync Labs' 2.0 model",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "video",
        "audio"
      ],
      "properties": {
        "audio": {
          "type": "string",
          "title": "Audio",
          "format": "uri",
          "description": "Input audio file (.wav)"
        },
        "video": {
          "type": "string",
          "title": "Video",
          "format": "uri",
          "description": "Input video file (.mp4)"
        },
        "sync_mode": {
          "allOf": [
            {
              "$ref": "#/components/schemas/sync_mode"
            }
          ],
          "default": "loop",
          "x-order": 2,
          "description": "Lipsync mode when audio and video durations are out of sync"
        },
        "temperature": {
          "type": "number",
          "title": "Temperature",
          "default": 0.5,
          "maximum": 1,
          "minimum": 0,
          "description": "How expressive lipsync can be (0-1)"
        },
        "active_speaker": {
          "type": "boolean",
          "title": "Active Speaker",
          "default": false,
          "description": "Whether to detect active speaker (i.e. whoever is speaking in the clip will be used for lipsync)"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:30.104Z"
  },
  {
    "modelId": "sync/lipsync-2-pro",
    "name": "Lipsync2Pro",
    "category": "lipsync",
    "description": "Studio-grade lipsync in minutes, not weeks",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "video",
        "audio"
      ],
      "properties": {
        "audio": {
          "type": "string",
          "title": "Audio",
          "format": "uri",
          "description": "Input audio file (.wav)"
        },
        "video": {
          "type": "string",
          "title": "Video",
          "format": "uri",
          "description": "Input video file (.mp4)"
        },
        "sync_mode": {
          "allOf": [
            {
              "$ref": "#/components/schemas/sync_mode"
            }
          ],
          "default": "loop",
          "x-order": 2,
          "description": "Lipsync mode when audio and video durations are out of sync"
        },
        "temperature": {
          "type": "number",
          "title": "Temperature",
          "default": 0.5,
          "maximum": 1,
          "minimum": 0,
          "description": "How expressive lipsync can be (0-1)"
        },
        "active_speaker": {
          "type": "boolean",
          "title": "Active Speaker",
          "default": false,
          "description": "Whether to detect active speaker (i.e. whoever is speaking in the clip will be used for lipsync)"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:30.377Z"
  },
  {
    "modelId": "bytedance/latentsync",
    "name": "LatentSync",
    "category": "lipsync",
    "description": "LatentSync: generate high-quality lip sync animations",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "properties": {
        "seed": {
          "type": "integer",
          "title": "Seed",
          "default": 0,
          "x-order": 3,
          "description": "Set to 0 for Random seed"
        },
        "audio": {
          "type": "string",
          "title": "Audio",
          "format": "uri",
          "x-order": 1,
          "description": "Input audio to "
        },
        "video": {
          "type": "string",
          "title": "Video",
          "format": "uri",
          "x-order": 0,
          "description": "Input video"
        },
        "guidance_scale": {
          "type": "number",
          "title": "Guidance Scale",
          "default": 1,
          "maximum": 10,
          "minimum": 0,
          "x-order": 2,
          "description": "Guidance scale"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:30.556Z"
  },
  {
    "modelId": "pixverse/lipsync",
    "name": "PixverseLipsync",
    "category": "lipsync",
    "description": "Generate realistic lipsync animations from audio for high-quality synchronization",
    "inputSchema": {
      "type": "object",
      "title": "Input",
      "required": [
        "video",
        "audio"
      ],
      "properties": {
        "audio": {
          "type": "string",
          "title": "Audio",
          "format": "uri",
          "x-order": 1,
          "description": "Audio file to upload to PixVerse as media"
        },
        "video": {
          "type": "string",
          "title": "Video",
          "format": "uri",
          "x-order": 0,
          "description": "Video file to upload to PixVerse as media"
        }
      }
    },
    "outputSchema": {
      "type": "string",
      "title": "Output",
      "format": "uri"
    },
    "fetchedAt": "2026-01-16T03:17:30.741Z"
  }
]